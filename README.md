# NLP Project: Tr√≠ch xu·∫•t thu·∫≠t ng·ªØ C√¥ng ngh·ªá (Technology Term Extraction)

D·ª± √°n m√¥n h·ªçc X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP), x√¢y d·ª±ng ·ª©ng d·ª•ng Web tr√≠ch xu·∫•t c√°c thu·∫≠t ng·ªØ chuy√™n ng√†nh c√¥ng ngh·ªá (v√≠ d·ª•: "tr√≠ tu·ªá nh√¢n t·∫°o", "m√¥ h√¨nh ng√¥n ng·ªØ", "big data"...) t·ª´ vƒÉn b·∫£n ti·∫øng Vi·ªát.

D·ª± √°n so s√°nh hi·ªáu qu·∫£ gi·ªØa c√°c ph∆∞∆°ng ph√°p **Machine Learning truy·ªÅn th·ªëng** v√† **Deep Learning**.

![Python](https://img.shields.io/badge/Python-3.10-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.9+-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)

## üìÇ C·∫•u tr√∫c d·ª± √°n

D·ª± √°n ƒë∆∞·ª£c t·ªï ch·ª©c th√†nh 3 th∆∞ m·ª•c ch√≠nh:

```text
NLP-app/
‚îú‚îÄ‚îÄ database/                # D·ªÆ LI·ªÜU
‚îÇ   ‚îî‚îÄ‚îÄ (Ch·ª©a 2000 c√¢u vƒÉn b·∫£n ti·∫øng Vi·ªát th√¥/raw data)
‚îÇ
‚îú‚îÄ‚îÄ training/                # HU·∫§N LUY·ªÜN M√î H√åNH
‚îÇ   ‚îú‚îÄ‚îÄ combined_data.json   # File d·ªØ li·ªáu 2099 c√¢u vƒÉn b·∫£n ti·∫øng vi·ªát ƒë√£ g·∫Øn nh√£n
‚îÇ   ‚îú‚îÄ‚îÄ DATA TEST POS TAGGING.xlsx #File 120 c√¢u vƒÉn b·∫£n ti·∫øng vi·ªát d√πng ƒë·ªÉ test m√¥ h√¨nh
‚îÇ   ‚îú‚îÄ‚îÄ POS_TAGGING.ipynb    # Code ch√≠nh ph·ª• tr√°ch vi·ªác hu·∫•n luy·ªán v√† ch·∫•m ƒëi·ªÉm m√¥ h√¨nh
‚îÇ   ‚îú‚îÄ‚îÄ ket_qua_chi_tiet.txt # ƒêi·ªÉm c·ªßa 4 m√¥ h√¨nh ML v√† 1 m√¥ h√¨nh DL sau hu·∫•n luy·ªán
‚îÇ   ‚îú‚îÄ‚îÄ TEST_POS_SVM_GOLD.json
‚îÇ   ‚îî‚îÄ‚îÄ deployment_resources/# Ch·ª©a c√°c file m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
‚îÇ       ‚îú‚îÄ‚îÄ bilstm.h5        # Model Bi-LSTM
‚îÇ       ‚îú‚îÄ‚îÄ svm_final.joblib # Model SVM
‚îÇ       ‚îú‚îÄ‚îÄ rf_final.joblib  # Model Random Forest (C·∫ßn t·∫£i th·ªß c√¥ng)
‚îÇ       ‚îú‚îÄ‚îÄ label_encoder.joblib 
‚îÇ       ‚îú‚îÄ‚îÄ logreg_final.joblib
‚îÇ       ‚îú‚îÄ‚îÄ max_len.json
‚îÇ       ‚îú‚îÄ‚îÄ nb_final.joblib
‚îÇ       ‚îú‚îÄ‚îÄ phrase_vocab.pkl
‚îÇ       ‚îú‚îÄ‚îÄ tag2idx.json
‚îÇ       ‚îú‚îÄ‚îÄ word2idx.json
‚îÇ       ‚îî‚îÄ‚îÄ vec_full.joblib
‚îÇ
‚îú‚îÄ‚îÄ application/             # ·ª®NG D·ª§NG DEMO (STREAMLIT)
‚îÇ   ‚îú‚îÄ‚îÄ app.py               # File ch√≠nh ƒë·ªÉ ch·∫°y ·ª©ng d·ª•ng
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt     # Danh s√°ch th∆∞ vi·ªán c·∫ßn thi·∫øt
‚îÇ   ‚îî‚îÄ‚îÄ deployment_resources/# Ch·ª©a c√°c file m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
‚îÇ       ‚îú‚îÄ‚îÄ bilstm.h5        # Model Bi-LSTM
‚îÇ       ‚îú‚îÄ‚îÄ svm_final.joblib # Model SVM
‚îÇ       ‚îú‚îÄ‚îÄ rf_final.joblib  # Model Random Forest (C·∫ßn t·∫£i th·ªß c√¥ng)
‚îÇ       ‚îú‚îÄ‚îÄ label_encoder.joblib 
‚îÇ       ‚îú‚îÄ‚îÄ logreg_final.joblib
‚îÇ       ‚îú‚îÄ‚îÄ max_len.json
‚îÇ       ‚îú‚îÄ‚îÄ nb_final.joblib
‚îÇ       ‚îú‚îÄ‚îÄ phrase_vocab.pkl
‚îÇ       ‚îú‚îÄ‚îÄ tag2idx.json
‚îÇ       ‚îú‚îÄ‚îÄ word2idx.json
‚îÇ       ‚îî‚îÄ‚îÄ vec_full.joblib
‚îÇ
‚îú‚îÄ‚îÄ venv/                    # M√¥i tr∆∞·ªùng ·∫£o (Kh√¥ng l∆∞u tr√™n Git)
‚îî‚îÄ‚îÄ README.md                # H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng

```

## ‚ú® T√≠nh nƒÉng & M√¥ h√¨nh

H·ªá th·ªëng ƒë√°p ·ª©ng y√™u c·∫ßu s·ª≠ d·ª•ng **3 m√¥ h√¨nh Machine Learning** v√† **1 m√¥ h√¨nh Deep Learning**:

1. **Machine Learning:**
* Support Vector Machine (SVM)
* Logistic Regression
* Random Forest
* Naive Bayes


2. **Deep Learning:**
* Bi-LSTM (Bidirectional Long Short-Term Memory)



## üõ† Y√™u c·∫ßu h·ªá th·ªëng (Quan tr·ªçng)

ƒê·ªÉ ƒë·∫£m b·∫£o t∆∞∆°ng th√≠ch v·ªõi c√°c m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán (ƒë·∫∑c bi·ªát l√† TensorFlow), b·∫Øt bu·ªôc s·ª≠ d·ª•ng:

* **Python:** Phi√™n b·∫£n **3.10** (Khuy√™n d√πng 3.10.11).
* **H·ªá ƒëi·ªÅu h√†nh:** Windows, macOS, ho·∫∑c Linux.

## üöÄ H∆∞·ªõng d·∫´n C√†i ƒë·∫∑t & Ch·∫°y

### B∆∞·ªõc 1: Clone d·ª± √°n

```
git clone https://github.com/Sunphuynx/NLP-app.git
cd NLP-app

```

### B∆∞·ªõc 2: T·∫°o v√† k√≠ch ho·∫°t m√¥i tr∆∞·ªùng ·∫£o

* **Windows:**
```
# ƒê·∫£m b·∫£o d√πng Python 3.10
py -3.10 -m venv venv
.\venv\Scripts\activate

```


* **macOS / Linux:**
```
python3.10 -m venv venv
source venv/bin/activate

```



### B∆∞·ªõc 3: C√†i ƒë·∫∑t th∆∞ vi·ªán

L∆∞u √Ω file `requirements.txt` n·∫±m trong th∆∞ m·ª•c `application`:

```
pip install -r application/requirements.txt

```

### B∆∞·ªõc 4: T·∫£i b·ªï sung Model n·∫∑ng (B·∫ÆT BU·ªòC)

Do gi·ªõi h·∫°n c·ªßa GitHub, file m√¥ h√¨nh **Random Forest (`rf_final.joblib`)** (>100MB) kh√¥ng c√≥ s·∫µn trong m√£ ngu·ªìn n√†y.

1. Li√™n h·ªá nh√≥m ph√°t tri·ªÉn ho·∫∑c truy c·∫≠p [Link Google Drive n√†y](https://drive.google.com/file/d/1qK4AYXL4uhq_oRXQ4QqLuChW7VZRBtzu/view?usp=sharing) ƒë·ªÉ t·∫£i file `rf_final.joblib`.
2. Copy file t·∫£i v·ªÅ v√†o th∆∞ m·ª•c: `application/deployment_resources/`

### B∆∞·ªõc 5: Ch·∫°y ·ª©ng d·ª•ng

Do m√£ ngu·ªìn ·ª©ng d·ª•ng n·∫±m trong th∆∞ m·ª•c `application`, b·∫°n c·∫ßn di chuy·ªÉn v√†o ƒë√≥ tr∆∞·ªõc khi ch·∫°y:

```
cd application
streamlit run app.py

```

Tr√¨nh duy·ªát s·∫Ω t·ª± ƒë·ªông m·ªü t·∫°i `http://localhost:8501`.

---

## ‚ö†Ô∏è C√°c l∆∞u √Ω kh·∫Øc ph·ª•c l·ªói th∆∞·ªùng g·∫∑p

**1. L·ªói `ModuleNotFoundError: No module named 'numpy._core'`**

* **Nguy√™n nh√¢n:** Xung ƒë·ªôt gi·ªØa model train b·∫±ng Numpy 2.0 v√† App ch·∫°y Numpy 1.x.
* **Kh·∫Øc ph·ª•c:** M√£ ngu·ªìn `app.py` hi·ªán t·∫°i ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ƒë·ªÉ t∆∞∆°ng th√≠ch. N·∫øu v·∫´n b·ªã, h√£y ƒë·∫£m b·∫£o b·∫°n ƒëang c√†i ƒë√∫ng c√°c phi√™n b·∫£n trong `requirements.txt`.

**2. L·ªói kh√¥ng t√¨m th·∫•y file `app.py`**

* H√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ ch·∫°y l·ªánh `cd application` tr∆∞·ªõc khi g√µ `streamlit run app.py`.

**3. WordCloud b·ªã l·ªói √¥ vu√¥ng (‚ñ°‚ñ°‚ñ°)**

* M√°y thi·∫øu font ti·∫øng Vi·ªát. H√£y t·∫£i file font `Roboto.ttf` v√† b·ªè v√†o th∆∞ m·ª•c `application/deployment_resources/`.

---

**Nh√≥m th·ª±c hi·ªán:**

* [Ph·∫°m Duy Ho√†ng]
* [Ph√πng Ch√≠ T√¢m]
* [Nguy·ªÖn Minh Khoa]
* [Bi·ªán B√πi Duy Quang]

```

```
